{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 734,
   "id": "924a538a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tkinter as tk\n",
    "from tkinter import Grid\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from numpy.core.fromnumeric import argmin\n",
    "from numpy import mean, std, max\n",
    "import seaborn as sns\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from fastdtw import fastdtw\n",
    "from scipy.spatial.distance import euclidean\n",
    "import math\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "b75c3646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created\n"
     ]
    }
   ],
   "source": [
    "ref_dir = 'H:/Jupyter_Notebooks/DSP Project/records mats/Team2_Ref/'\n",
    "test_dir = 'H:/Jupyter_Notebooks/DSP Project/records mats/All_Records/'\n",
    "try:\n",
    "    os.mkdir(ref_dir)\n",
    "    os.mkdir(test_dir)\n",
    "except:\n",
    "    print(\"Created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 877,
   "id": "a0fc1754",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collectWords(test_dir, ref_dir):\n",
    "    ref_words, ref_mats = [], []\n",
    "    test_words, test_mats = [], []\n",
    "    for file in os.listdir(ref_dir):\n",
    "        ref_words.append(file)\n",
    "        ref_mats.append(scipy.io.loadmat(ref_dir+file))\n",
    "\n",
    "    for file in os.listdir(test_dir):\n",
    "        test_words.append(file)\n",
    "        test_mats.append(scipy.io.loadmat(test_dir+file))\n",
    "        \n",
    "    return (ref_words, ref_mats), (test_words, test_mats)\n",
    "#--------------------------------------------------------------------------------------------------------------------------------\n",
    "def featureScaling(test_mats, ref_mats):\n",
    "    df_total = pd.DataFrame()\n",
    "    for mat in ref_mats:\n",
    "        single_df = pd.DataFrame(mat['featuresMatrix'])\n",
    "        df_total = pd.concat((df_total, single_df))     \n",
    "    for mat in test_mats:\n",
    "        single_df = pd.DataFrame(mat['featuresMatrix'])\n",
    "        df_total = pd.concat((df_total, single_df))\n",
    "        \n",
    "    df_total2 = df_total.copy()\n",
    "    SS = StandardScaler()\n",
    "    MS = MinMaxScaler()\n",
    "    SS.fit(df_total[df_total.columns])\n",
    "    MS.fit(df_total2[df_total2.columns])\n",
    "    df_total[df_total.columns] = SS.fit_transform(df_total[df_total.columns])\n",
    "    df_total2[df_total2.columns] = MS.fit_transform(df_total2[df_total2.columns])\n",
    "    return SS, MS, df_total, df_total2\n",
    "#--------------------------------------------------------------------------------------------------------------------------------\n",
    "def find_Group_Student(group_num, student_num, words, mat_files, StandardS):\n",
    "    assert (int(student_num)>=1 and int(student_num)<=5), \"Error in student number\"\n",
    "    assert (int(group_num)>=1 and int(group_num)<=14), \"Error in group number\"\n",
    "    assert (len(words) == len(mat_files)), \"Not equal in length\"\n",
    "    \n",
    "    selected_words_GS, selected_mats_GS = [], []\n",
    "    for i, (word, mat) in enumerate(zip(words, mat_files)):\n",
    "        if ('G'+ str(group_num)) + ('S'+ str(student_num)) in word:\n",
    "            selected_words_GS.append(word)\n",
    "            mat['featuresMatrix'] = StandardS.transform(mat['featuresMatrix'])\n",
    "            selected_mats_GS.append(mat['featuresMatrix'])\n",
    "    assert (len(selected_mats_GS) == len(selected_words_GS)), \"Output files not equal in length ?????\"\n",
    "    return (selected_words_GS, selected_mats_GS)\n",
    "#--------------------------------------------------------------------------------------------------------------------------------    \n",
    "def find_Pair_Word_Gender(pair_num, word_num, gender, words, mat_files, StandardS):\n",
    "    assert (word_num==1 or word_num==2), \"Error in word number\"\n",
    "    assert (int(pair_num)>=0 and int(pair_num)<=62), \"Error in pair number\"\n",
    "    assert (gender=='F' or gender=='M' or gender=='C'), \"Error in gender\"\n",
    "    assert (len(words) == len(mat_files)), \"Not equal in length\"\n",
    "    assert (word_num == 1 or int(pair_num) != 62), \"Last pair only have 1 word\"\n",
    "    \n",
    "    selected_word_PWG, selected_mat_PWG = [], []\n",
    "    for i, (word, mat) in enumerate(zip(words, mat_files)):\n",
    "        if ('P'+ str(pair_num)) + ('W'+ str(word_num)) in word and word.find(gender, 4, 6)!=-1:\n",
    "            selected_word_PWG.append(word)\n",
    "            mat['featuresMatrix'] = StandardS.transform(mat['featuresMatrix'])\n",
    "            selected_mat_PWG.append(mat['featuresMatrix'])\n",
    "    assert (len(selected_mat_PWG) == len(selected_word_PWG)), \"Output files not equal in length ?????\"\n",
    "    return (selected_word_PWG, selected_mat_PWG)\n",
    "#--------------------------------------------------------------------------------------------------------------------------------\n",
    "def dtw(reference, sequence ,dist = np.linalg.norm, reconstruct=False):\n",
    "    reference = np.array(reference)\n",
    "    sequence = np.array(sequence)\n",
    "    assert np.shape(reference)[1] == np.shape(sequence)[1],\"reference and y must have the same number of columns\"\n",
    "    k = np.shape(reference)[1]\n",
    "    r, c = np.shape(sequence)[0], np.shape(reference)[0]\n",
    "    # assert r>=c//2 and r<=c*2, \"reference must have at least half as many rows as sequence\"\n",
    "    if not (r>=c//2 and r<=c*2):\n",
    "        # print(\"reference must have at least half as many rows as sequence\")\n",
    "        if reconstruct:\n",
    "            return np.inf, None, None\n",
    "        return np.inf\n",
    "\n",
    "    # Initialize the cost matrix\n",
    "    D = np.zeros((r+1,c+1))\n",
    "    D[0, 1:] = np.inf\n",
    "    D[1:, 0] = np.inf\n",
    "    D[0,0] = 0\n",
    "\n",
    "    # Initialize the distance matrix\n",
    "    d = np.zeros((r,c))\n",
    "\n",
    "    # setting unwanted region to infinity\n",
    "    j_limit = 0\n",
    "    for i in range(r):\n",
    "        j_limit += 2\n",
    "        for j in range(j_limit,c):\n",
    "            d[i,j] = np.inf\n",
    "    i_limit = 0\n",
    "    for j in range(c):\n",
    "        i_limit += 2\n",
    "        for i in range(i_limit,r):\n",
    "            d[i,j] = np.inf\n",
    "    j_limit = c\n",
    "    for i in reversed(range(r)):\n",
    "        j_limit -= 2\n",
    "        for j in reversed(range(j_limit)):\n",
    "            d[i,j] = np.inf\n",
    "    i_limit = r\n",
    "    for j in reversed(range(c)):\n",
    "        i_limit -= 2\n",
    "        for i in reversed(range(i_limit)):\n",
    "            d[i,j] = np.inf\n",
    "    \n",
    "    # initializing optimal path matrix\n",
    "    B = np.zeros((r,c,2),dtype=np.int)\n",
    "    B[0,0] = [0,0]\n",
    "\n",
    "    # computing cost matrix and optimal path matrix\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            if d[i,j] == np.inf:\n",
    "                D[i+1,j+1] = np.inf\n",
    "                continue\n",
    "            d[i,j] = dist(reference[j]-sequence[i])\n",
    "            if (B[i-1,j,0] == i-2 and B[i-1,j,1] == j) and (B[i,j-1,0] == i and B[i,j-1,1] == j-2):\n",
    "                D[i+1,j+1] = d[i,j]+D[i,j]\n",
    "                B[i,j] = [i-1,j-1]\n",
    "            elif B[i-1,j,0] == i-2 and B[i-1,j,1] == j:\n",
    "                D[i+1,j+1] = d[i,j]+min(D[i+1,j],D[i,j])\n",
    "                index = argmin([D[i+1,j],D[i,j]])\n",
    "                B[i,j] = [i-index,j-1]\n",
    "            elif B[i,j-1,0] == i and B[i,j-1,1] == j-2:\n",
    "                D[i+1,j+1] = d[i,j]+min(D[i,j],D[i,j+1])\n",
    "                index = argmin([D[i,j+1],D[i,j]])\n",
    "                B[i,j] = [i-1, j-index]\n",
    "            else:\n",
    "                D[i+1,j+1] = d[i,j]+min(D[i+1,j],D[i,j+1],D[i,j])\n",
    "                index = argmin([D[i+1,j],D[i,j+1],D[i,j]])\n",
    "                B[i,j] = [i-int(index>0), j-1+int(index==1)]\n",
    "\n",
    "    if reconstruct:\n",
    "        i = r-1\n",
    "        j = c-1\n",
    "        path = [(i,j)]\n",
    "        while i>0 or j>0:\n",
    "            step = (B[i,j,0],B[i,j,1])\n",
    "            path.insert(0, (step[0],step[1]))\n",
    "            i,j = step\n",
    "        constructed_sequence = np.zeros((c,k))\n",
    "        skipNext = False\n",
    "        k=0\n",
    "        for i,j in path:\n",
    "            if not skipNext:\n",
    "                if k+1<c and k+1<len(path) and j == path[k+1][1]:\n",
    "                    constructed_sequence[j] = (sequence[i]+sequence[i+1])/2\n",
    "                    skipNext = True\n",
    "                else:\n",
    "                    constructed_sequence[j] = sequence[i]\n",
    "            else:\n",
    "                skipNext = False\n",
    "            k += 1\n",
    "        distances = np.zeros((c,1),np.float64)\n",
    "        for i in range(c):\n",
    "            distances[i] = dist(reference[i,]-constructed_sequence[i])   \n",
    "        return D[r,c],constructed_sequence, distances\n",
    "    return D[r, c]\n",
    "#--------------------------------------------------------------------------------------------------------------------------------\n",
    "def calc_dtw(pair_num, gender, Scaler, word_num=[1, 2]):\n",
    "    dtw1_1, dtw1_2, dtw2_1, dtw2_2 = [], [], [], []     \n",
    "    for num in word_num:\n",
    "        if num==1:\n",
    "            ref_word1, ref_mat1 = find_Pair_Word_Gender(pair_num = str(pair_num), word_num = num, \n",
    "                                                        gender=gender, words=ref_words, mat_files=ref_mats, StandardS=Scaler)\n",
    "            test_words1, test_mats1 = find_Pair_Word_Gender(pair_num = str(pair_num), word_num = num, \n",
    "                                                        gender=gender, words=test_words, mat_files=test_mats, StandardS=Scaler)\n",
    "        elif num==2: #instead of else, doesn't matter don't care.\n",
    "            ref_word2, ref_mat2 = find_Pair_Word_Gender(pair_num = str(pair_num), word_num = num, \n",
    "                                                         gender=gender, words=ref_words, mat_files=ref_mats, StandardS=Scaler)\n",
    "            test_words2, test_mats2 = find_Pair_Word_Gender(pair_num = str(pair_num), word_num = num, \n",
    "                                                        gender=gender, words=test_words, mat_files=test_mats, StandardS=Scaler) \n",
    "                                                        \n",
    "    for i, (mat1, mat2) in enumerate(zip(test_mats1[:], test_mats2[:])):\n",
    "        dtw1_1.append(dtw(ref_mat1[0], mat1, dist=np.linalg.norm))\n",
    "        dtw1_2.append(dtw(ref_mat1[0], mat2, dist=np.linalg.norm))    \n",
    "        dtw2_1.append(dtw(ref_mat2[0], mat1, dist=np.linalg.norm))\n",
    "        dtw2_2.append(dtw(ref_mat2[0], mat2, dist=np.linalg.norm))\n",
    "        # dtw1_1.append(fastdtw(ref_mat1[0], mat1, dist=euclidean)[0])\n",
    "        # dtw1_2.append(fastdtw(ref_mat1[0], mat2, dist=euclidean)[0])    \n",
    "        # dtw2_1.append(fastdtw(ref_mat2[0], mat1, dist=euclidean)[0])\n",
    "        # dtw2_2.append(fastdtw(ref_mat2[0], mat2, dist=euclidean)[0])\n",
    "            \n",
    "    return dtw1_1, dtw1_2, dtw2_1, dtw2_2\n",
    "#--------------------------------------------------------------------------------------------------------------------------------\n",
    "def detect_outliers(data):\n",
    "    indices = []\n",
    "    data_mean, data_std = mean(data), std(data)\n",
    "    cut_off = data_std * 3 #3\n",
    "    lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "    outliers = [x for x in data if x < lower or x > upper]\n",
    "    if outliers == []:\n",
    "        return\n",
    "\n",
    "    for outlier in outliers:\n",
    "        indices.append(data.index(outlier))\n",
    "\n",
    "    return indices\n",
    "#--------------------------------------------------------------------------------------------------------------------------------\n",
    "def remove_elements(data, indices):\n",
    "    if indices == None or indices == [] or indices == 'N':\n",
    "        return \n",
    "\n",
    "    else:\n",
    "        new_indices = list(set(indices))\n",
    "        for index in reversed(indices):\n",
    "            data.pop(index)\n",
    "\n",
    "    return data\n",
    "#--------------------------------------------------------------------------------------------------------------------------------\n",
    "def detectandremove(data):\n",
    "    indices = []\n",
    "    data_mean, data_std = mean(data), std(data)\n",
    "    #cut_off = data_std * 3\n",
    "    lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "    outliers = [x for x in data if x < lower or x > upper]\n",
    "    if outliers == []:\n",
    "        return\n",
    "\n",
    "    for outlier in outliers:\n",
    "        indices.append(data.index(outlier))\n",
    "\n",
    "    for index in reversed(indices):\n",
    "        data.pop(index)\n",
    "\n",
    "    return data, indices\n",
    " #--------------------------------------------------------------------------------------------------------------------------------       \n",
    "def detect_th(data1, data2):\n",
    "    m1, m2 = mean(data1), mean(data2)\n",
    "    th = (m1+m2)*0.7 #*0.7\n",
    "    return th\n",
    "#--------------------------------------------------------------------------------------------------------------------------------\n",
    "def Judgement(threshold, dtw1, dtw2, pair, gender):\n",
    "    total = 0\n",
    "    correct, wrong, other = 0, 0, 0\n",
    "    word1, word2 = 0, 0\n",
    "    #dtw1_1 < dtw1_2 and <threshold ->Word1, else if dtw1_1 > dtw1_2 and <threshold ->Word2\n",
    "    #else ->Other\n",
    "    arr = np.zeros((6, 1))\n",
    "\n",
    "    for i, (one, two) in enumerate(zip(dtw1, dtw2)):\n",
    "        if one < two and one < threshold:\n",
    "            correct+=1\n",
    "            word1+=1\n",
    "        elif one > two and one < threshold:\n",
    "            wrong+=1\n",
    "            word2+=1\n",
    "        else:\n",
    "            other+=1\n",
    "            wrong+=1\n",
    "        total+=1\n",
    "    other_word = wrong-other    \n",
    "    arr = [pair, gender, total, other, other_word, correct, wrong]   \n",
    "\n",
    "    return arr\n",
    "#--------------------------------------------------------------------------------------------------------------------------------\n",
    "def to_numeric(df, features):\n",
    "    df[features] = df[features].apply(pd.to_numeric)\n",
    "    return df\n",
    "\n",
    "    return df\n",
    "#---------------------------------------------------------------------------------------------------------------------------------\n",
    "def adjustDataFrame(df):\n",
    "    Word_Num = df.index+1\n",
    "    df.set_index(df['pair'], inplace=True)\n",
    "    df.insert(0, 'Word_Number', Word_Num)\n",
    "    df.drop(columns=['pair'], inplace=True)\n",
    "    return df\n",
    "    \n",
    "#--------------------------------------------------------------------------------------------------------------------------------\n",
    "def UsefulFeatures(df, features):\n",
    "    df.loc['Summation',:] = df[features].sum(axis=0)\n",
    "    df.loc[:,'Summation'] = df[features].sum(axis=1)\n",
    "    df['Correct_Percentage'] = df['correct']/df['total']\n",
    "    df['Wrong_Percentage'] = df['wrong']/df['total']\n",
    "    df.drop(columns=['Summation'], inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "89529547",
   "metadata": {},
   "outputs": [],
   "source": [
    "(ref_words, ref_mats), (test_words, test_mats) = collectWords(test_dir, ref_dir)\n",
    "SS, MS, df1, df2 = featureScaling(test_mats, ref_mats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2922c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "types = ['M', 'F', 'C']\n",
    "df_M =  pd.DataFrame(columns=['pair', 'type', 'total', 'other', 'other_word', 'correct', 'wrong'])\n",
    "df_F =  pd.DataFrame(columns=['pair', 'type', 'total', 'other', 'other_word', 'correct', 'wrong'])\n",
    "df_C =  pd.DataFrame(columns=['pair', 'type', 'total', 'other', 'other_word', 'correct', 'wrong'])\n",
    "total_ths_M,  total_ths_F, total_ths_C = [], [], []\n",
    "words = pd.read_csv('words.csv')\n",
    "pairs = [i for i in range(62)]\n",
    "pairs.pop(0)\n",
    "pairs = list(map(str, pairs))\n",
    "for i, pair in enumerate(pairs):\n",
    "    if i == 9:\n",
    "        break\n",
    "    pairs[i] = '0'+ pair\n",
    "total_ths = []\n",
    "\n",
    "for gender in types:\n",
    "    print(f'Start Type {gender}')\n",
    "    for pair in pairs:\n",
    "        print(f'Start Pair {pair}')\n",
    "        dtw1_1, dtw1_2, dtw2_1, dtw2_2 = calc_dtw(pair_num=pair, gender=gender, Scaler= SS, word_num=[1, 2])\n",
    "        a_infs1 = np.where(np.isinf(dtw1_1))\n",
    "        a_infs2 = np.where(np.isinf(dtw1_2))\n",
    "        a_infs3 = np.where(np.isinf(dtw2_1))\n",
    "        a_infs4 = np.where(np.isinf(dtw2_2))\n",
    "        for data, index in zip([dtw1_1, dtw1_2, dtw2_1, dtw2_2], [a_infs1, a_infs2, a_infs3, a_infs4]):\n",
    "            data = remove_elements(data, list(index[0]))\n",
    "        \n",
    "        indices_total = []\n",
    "        counter = 0\n",
    "        condition = False\n",
    "        while not condition:\n",
    "            for i, data in enumerate([dtw1_1, dtw1_2, dtw2_1, dtw2_2]):\n",
    "                indices = detect_outliers(data)\n",
    "                if indices == None:\n",
    "                    indices = 'N'\n",
    "                indices_total.extend(indices)\n",
    "                data = remove_elements(data, indices)\n",
    "            counter+=1    \n",
    "            if counter > 1:\n",
    "                condition = any((indices_total[j]=='N' and indices_total[j+1]=='N' and indices_total[j+2]=='N') for j in range(1, len(indices_total)-3))\n",
    "\n",
    "        lengths = [len(dtw1_1), len(dtw1_2), len(dtw2_1), len(dtw2_2)]\n",
    "        max_length = [length for length in lengths if length==lengths[np.argmin(lengths)]]\n",
    "        random_samples = list(np.random.randint(low=0, high=max_length[0], size=20))\n",
    "        thresholds = []\n",
    "        dtw1_1n, dtw2_2n = [dtw1_1[i] for i in random_samples], [dtw2_2[i] for i in random_samples]\n",
    "        dtw1_2n, dtw2_1n = [dtw1_2[i] for i in random_samples], [dtw2_1[i] for i in random_samples]\n",
    "        thresholds.append(detect_th(dtw1_1n, dtw1_2n))\n",
    "        thresholds.append(detect_th(dtw2_2n, dtw2_1n))\n",
    "        if gender == 'M':\n",
    "            total_ths_M.append(thresholds)\n",
    "            array1 = Judgement(thresholds[0], dtw1_1, dtw1_2, pair=pair, gender=gender)\n",
    "            array2 = Judgement(thresholds[1], dtw2_2, dtw2_1, pair=pair, gender=gender)\n",
    "            arr = np.vstack((array1, array2))\n",
    "            df_M = pd.concat((df_M, pd.DataFrame(arr, columns=['pair', 'type', 'total', 'other', 'other_word', 'correct', 'wrong'])), axis=0)\n",
    "        elif gender == 'F':\n",
    "            total_ths_F.append(thresholds)\n",
    "            array1 = Judgement(thresholds[0], dtw1_1, dtw1_2, pair=pair, gender=gender)\n",
    "            array2 = Judgement(thresholds[1], dtw2_2, dtw2_1, pair=pair, gender=gender)\n",
    "            arr = np.vstack((array1, array2))\n",
    "            df_F = pd.concat((df_F, pd.DataFrame(arr, columns=['pair', 'type', 'total', 'other', 'other_word', 'correct', 'wrong'])), axis=0)\n",
    "        else:\n",
    "            total_ths_C.append(thresholds)\n",
    "            array1 = Judgement(thresholds[0], dtw1_1, dtw1_2, pair=pair, gender=gender)\n",
    "            array2 = Judgement(thresholds[1], dtw2_2, dtw2_1, pair=pair, gender=gender)\n",
    "            arr = np.vstack((array1, array2))\n",
    "            df_C = pd.concat((df_C, pd.DataFrame(arr, columns=['pair', 'type', 'total', 'other', 'other_word', 'correct', 'wrong'])), axis=0)  \n",
    "\n",
    "        print(f'End Pair {pair}')\n",
    "    print(f'End Type {gender}')\n",
    "\n",
    "df1 = df_M.copy()\n",
    "df2 = df_F.copy()\n",
    "df3 = df_C.copy()\n",
    "\n",
    "flat_list_M = [item for sublist in total_ths_M for item in sublist]\n",
    "flat_list_F = [item for sublist in total_ths_F for item in sublist]\n",
    "flat_list_C = [item for sublist in total_ths_C for item in sublist]\n",
    "df_M['Threshold'] = flat_list_M\n",
    "df_F['Threshold'] = flat_list_F\n",
    "df_C['Threshold'] = flat_list_C\n",
    "\n",
    "features = [col for col in df_C.columns if col not in ['type']]\n",
    "features2 = [col for col in df_C.columns if col not in ['type', 'pair']]\n",
    "for df in [df_M, df_F, df_C]:\n",
    "    df = to_numeric(df, features)\n",
    "    df = adjustDataFrame(df)\n",
    "    df = UsefulFeatures(df, features2)\n",
    "\n",
    "df_M.to_csv('df_M.csv')\n",
    "df_F.to_csv('df_F.csv')\n",
    "df_C.to_csv('df_C.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 883,
   "id": "b9222bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import messagebox, ttk\n",
    "class GUI(tk.Tk):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        tk.Tk.__init__(self, *args, **kwargs)\n",
    "        self.title(\"Speech Validation System\")\n",
    "        self.geometry(\"500x500\")\n",
    "        self.resizable(True,True)\n",
    "        self._frame = None\n",
    "        self.switch_frame(StartPage)\n",
    "\n",
    "    def switch_frame(self, frame_class, *args, **kwargs):\n",
    "        new_frame = frame_class(self)\n",
    "        if self._frame is not None:\n",
    "            self._frame.destroy()\n",
    "        self._frame = new_frame\n",
    "        self._frame.pack()\n",
    "\n",
    "    def get_accuracy(self, df):\n",
    "        messagebox.showinfo(\"Accuracy\", df['Correct_Percentage'].iloc[-1])\n",
    "\n",
    "    def getUsersAvg(self, df):\n",
    "        messagebox.showinfo(\"Average Users\", df['total'].iloc[0:122].mean())\n",
    "\n",
    "class StartPage(tk.Frame):\n",
    "    def __init__(self, master):\n",
    "        tk.Frame.__init__(self, master)\n",
    "        tk.Label(self, text=\"Hello and Welcome to my Humble System\").grid(column=0,row=0)\n",
    "        tk.Button(self, text=\"Select type please\",\n",
    "                  command=lambda: master.switch_frame(Type_Page)).grid(column=0,row=1)\n",
    "\n",
    "class Type_Page(tk.Frame):\n",
    "    def __init__(self, master):\n",
    "        tk.Frame.__init__(self, master)\n",
    "        tk.Label(self, text=\"Pick Type\").grid(column=0,row=0)\n",
    "        tk.Button(self, text=\"Male\", command=lambda: master.switch_frame(Male)).grid(column=0,row=1)\n",
    "        tk.Button(self, text=\"Child\", command=lambda: master.switch_frame(Child)).grid(column=0,row=2)\n",
    "        tk.Button(self, text=\"Female\", command=lambda: master.switch_frame(Female)).grid(column=0,row=3)\n",
    "        tk.Button(self, text=\"Return to Start Page\", command=lambda: master.switch_frame(StartPage)).grid(column=0,row=4)\n",
    "\n",
    "class Male(tk.Frame):\n",
    "\n",
    "    def show_option(self):\n",
    "        identifier = self.options.get()\n",
    "        self.text.delete(1.0, tk.END)\n",
    "        self.text.insert(tk.END, str(df_M[identifier]))\n",
    "\n",
    "    def __init__(self, master):\n",
    "        tk.Frame.__init__(self, master)\n",
    "        tk.Label(self, text=\"Male Page\").pack()\n",
    "        tk.Button(self, text=\"Show Total Accuracy\", pady=5, command=lambda: master.get_accuracy(df_M)).pack()\n",
    "        tk.Button(self, text=\"Show Average User Number\", pady=5, command=lambda: master.getUsersAvg(df_M)).pack()\n",
    "        tk.Button(self, text=\"Return To Previous Page\", pady=5, command=lambda: master.switch_frame(Type_Page)).pack()\n",
    "        tk.Button(self, text=\"Return to Start Page\", pady=5, command=lambda: master.switch_frame(StartPage)).pack()\n",
    "        tk.Label(self, text='Select option:').pack()\n",
    "        self.options = ttk.Combobox(self, values=list(df_M.columns))\n",
    "        self.options.pack()\n",
    "        tk.Button(self, text='Show option', command=self.show_option).pack()\n",
    "        self.text = tk.Text(self)\n",
    "        self.text.pack()\n",
    "\n",
    "\n",
    "\n",
    "class Female(tk.Frame):\n",
    "    def show_option(self):\n",
    "        identifier = self.options.get()\n",
    "        self.text.delete(1.0, tk.END)\n",
    "        self.text.insert(tk.END, str(df_F[identifier]))\n",
    "\n",
    "    def __init__(self, master):\n",
    "        tk.Frame.__init__(self, master)\n",
    "        tk.Label(self, text=\"Female Page\").pack(side=\"top\", fill=\"x\", pady=15)\n",
    "        tk.Button(self, text=\"Show Total Accuracy\", pady=5, command=lambda: master.get_accuracy(df_F)).pack()\n",
    "        tk.Button(self, text=\"Show Average User Number\", pady=5, command=lambda: master.getUsersAvg(df_C)).pack()\n",
    "        tk.Button(self, text=\"Return To Previous Page\", pady=5, command=lambda: master.switch_frame(Type_Page)).pack()\n",
    "        tk.Button(self, text=\"Return to Start Page\", pady=5, command=lambda: master.switch_frame(StartPage)).pack()\n",
    "        self.options = ttk.Combobox(self, values=list(df_F.columns))\n",
    "        self.options.pack()\n",
    "        tk.Button(self, text='Show option', command=self.show_option).pack()\n",
    "        self.text = tk.Text(self)\n",
    "        self.text.pack()\n",
    "\n",
    "class Child(tk.Frame):\n",
    "    def show_option(self):\n",
    "        identifier = self.options.get()\n",
    "        self.text.delete(1.0, tk.END)\n",
    "        self.text.insert(tk.END, str(df_C[identifier]))\n",
    "\n",
    "    def __init__(self, master):\n",
    "        tk.Frame.__init__(self, master)\n",
    "        tk.Label(self, text=\"Child Page\").pack(side=\"top\", fill=\"x\", pady=15)\n",
    "        tk.Button(self, text=\"Show Total Accuracy\", pady=5, command=lambda: master.get_accuracy(df_C)).pack()\n",
    "        tk.Button(self, text=\"Show Average User Number\", pady=5, command=lambda: master.getUsersAvg(df_C)).pack()\n",
    "        tk.Button(self, text=\"Return To Previous Page\", pady=5, command=lambda: master.switch_frame(Type_Page)).pack()\n",
    "        tk.Button(self, text=\"Return to Start Page\", pady=5, command=lambda: master.switch_frame(StartPage)).pack()\n",
    "        self.options = ttk.Combobox(self, values=list(df_C.columns))\n",
    "        self.options.pack()\n",
    "        tk.Button(self, text='Show option', command=self.show_option).pack()\n",
    "        self.text = tk.Text(self)\n",
    "        self.text.pack()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    App = GUI()\n",
    "    App.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2bf67b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
